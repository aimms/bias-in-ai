# bias-in-ai

![WebUI](https://img.shields.io/badge/UI-WebUI-success)

**Mirrored in:** https://github.com/aimms/--

**How-to:** https://how-to.aimms.com/Articles/--

## Story

At the end of 2017, the Civil Comments (https://medium.com/@aja_15265/saying-goodbye-to-civil-comments-41859d3a2b1d) platform shut down and released their ~2 million public comments in a lasting open archive. Jigsaw sponsored this effort and helped to comprehensively annotate the data.  In 2019, Kaggle held the Jigsaw Unintended Bias in Toxicity Classification (https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview) competition so that data scientists worldwide could work together to investigate ways to mitigate bias.

This project is able to load some of the data from the competition and connect with Python model. After typing a query, the code will run for approximately 30 seconds, when it finishes, you should see as output a message saying if the query you typed is "toxic" or "not toxic".